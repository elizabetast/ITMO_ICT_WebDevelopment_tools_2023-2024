{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to MkDocs For full documentation visit mkdocs.org . Commands mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs -h - Print help message and exit. Project layout mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"Welcome to MkDocs"},{"location":"#welcome-to-mkdocs","text":"For full documentation visit mkdocs.org .","title":"Welcome to MkDocs"},{"location":"#commands","text":"mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs -h - Print help message and exit.","title":"Commands"},{"location":"#project-layout","text":"mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"Project layout"},{"location":"task1/","text":"Task 1 \u041e\u043f\u0438\u0441\u0430\u043d\u0438\u0435 \u041d\u0430\u043f\u0438\u0448\u0438\u0442\u0435 \u0442\u0440\u0438 \u0440\u0430\u0437\u043b\u0438\u0447\u043d\u044b\u0445 \u043f\u0440\u043e\u0433\u0440\u0430\u043c\u043c\u044b \u043d\u0430 Python, \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u044e\u0449\u0438\u0435 \u043a\u0430\u0436\u0434\u044b\u0439 \u0438\u0437 \u043f\u043e\u0434\u0445\u043e\u0434\u043e\u0432: threading, multiprocessing \u0438 async. \u041a\u0430\u0436\u0434\u0430\u044f \u043f\u0440\u043e\u0433\u0440\u0430\u043c\u043c\u0430 \u0434\u043e\u043b\u0436\u043d\u0430 \u0440\u0435\u0448\u0430\u0442\u044c \u0441\u0447\u0438\u0442\u0430\u0442\u044c \u0441\u0443\u043c\u043c\u0443 \u0432\u0441\u0435\u0445 \u0447\u0438\u0441\u0435\u043b \u043e\u0442 1 \u0434\u043e 1000000. \u0420\u0430\u0437\u0434\u0435\u043b\u0438\u0442\u0435 \u0432\u044b\u0447\u0438\u0441\u043b\u0435\u043d\u0438\u044f \u043d\u0430 \u043d\u0435\u0441\u043a\u043e\u043b\u044c\u043a\u043e \u043f\u0430\u0440\u0430\u043b\u043b\u0435\u043b\u044c\u043d\u044b\u0445 \u0437\u0430\u0434\u0430\u0447 \u0434\u043b\u044f \u0443\u0441\u043a\u043e\u0440\u0435\u043d\u0438\u044f \u0432\u044b\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u044f. Async import asyncio import time async def calculate_partial_sum(start, end): partial_sum = sum(range(start, end)) return partial_sum async def calculate_sum(): num_tasks = 5 chunk_size = 1000000 // num_tasks tasks = [] start_time = time.time() for i in range(num_tasks): start = i * chunk_size + 1 end = (i + 1) * chunk_size + 1 if i < num_tasks - 1 else 1000001 task = asyncio.create_task(calculate_partial_sum(start, end)) tasks.append(task) partial_sums = await asyncio.gather(*tasks) total_sum = sum(partial_sums) end_time = time.time() print(\"Total sum (Async):\", total_sum) print(\"Time taken:\", end_time - start_time, \"seconds\") if __name__ == \"__main__\": asyncio.run(calculate_sum()) Multiprocessing import multiprocessing import time def calculate_partial_sum(start, end, result): partial_sum = sum(range(start, end)) result.put(partial_sum) def calculate_sum(): num_processes = 2 results = multiprocessing.Queue() processes = [] start_time = time.time() chunk_size = 1000000 // num_processes for i in range(num_processes): start = i * chunk_size + 1 end = (i + 1) * chunk_size + 1 if i < num_processes - 1 else 1000001 process = multiprocessing.Process(target=calculate_partial_sum, args=(start, end, results)) processes.append(process) process.start() for process in processes: process.join() end_time = time.time() total_sum = 0 while not results.empty(): total_sum += results.get() print(\"Total sum (Multiprocessing):\", total_sum) print(\"Time taken:\", end_time - start_time, \"seconds\") if __name__ == \"__main__\": calculate_sum() Threading import threading import time def calculate_partial_sum(start, end, result): partial_sum = sum(range(start, end)) result.append(partial_sum) def calculate_sum(): num_threads = 4 results = [] start_time = time.time() threads = [] chunk_size = 1000000 // num_threads for i in range(num_threads): start = i * chunk_size + 1 end = (i + 1) * chunk_size + 1 if i < num_threads - 1 else 1000001 thread = threading.Thread(target=calculate_partial_sum, args=(start, end, results)) threads.append(thread) thread.start() for thread in threads: thread.join() end_time = time.time() total_sum = sum(results) print(\"Total sum (Threading):\", total_sum) print(\"Time taken:\", end_time - start_time, \"seconds\") if __name__ == \"__main__\": calculate_sum() \u0420\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u044b \u041f\u043e \u0432\u0440\u0435\u043c\u0435\u043d\u0438 \u0432\u044b\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u044f \u0441\u0438\u043b\u044c\u043d\u043e \u043f\u0440\u043e\u0438\u0433\u0440\u044b\u0432\u0430\u0435\u0442 multiprocessing (\u0438\u0437-\u0437\u0430 \u043f\u043e\u0442\u0440\u0430\u0447\u0435\u043d\u043d\u043e\u0433\u043e \u043d\u0430 \u0441\u043e\u0437\u0434\u0430\u043d\u0438\u0435 \u043f\u043e\u0442\u043e\u043a\u043e\u0432 \u0440\u0435\u0441\u0443\u0440\u0441\u043e\u0432), async \u0438 threading \u043e\u0442\u0440\u0430\u0431\u043e\u0442\u0430\u043b\u0438 \u043f\u043e\u0447\u0442\u0438 \u043e\u0434\u0438\u043d\u0430\u043a\u043e\u0432\u043e.","title":"Task 1"},{"location":"task1/#task-1","text":"","title":"Task 1"},{"location":"task1/#_1","text":"\u041d\u0430\u043f\u0438\u0448\u0438\u0442\u0435 \u0442\u0440\u0438 \u0440\u0430\u0437\u043b\u0438\u0447\u043d\u044b\u0445 \u043f\u0440\u043e\u0433\u0440\u0430\u043c\u043c\u044b \u043d\u0430 Python, \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u044e\u0449\u0438\u0435 \u043a\u0430\u0436\u0434\u044b\u0439 \u0438\u0437 \u043f\u043e\u0434\u0445\u043e\u0434\u043e\u0432: threading, multiprocessing \u0438 async. \u041a\u0430\u0436\u0434\u0430\u044f \u043f\u0440\u043e\u0433\u0440\u0430\u043c\u043c\u0430 \u0434\u043e\u043b\u0436\u043d\u0430 \u0440\u0435\u0448\u0430\u0442\u044c \u0441\u0447\u0438\u0442\u0430\u0442\u044c \u0441\u0443\u043c\u043c\u0443 \u0432\u0441\u0435\u0445 \u0447\u0438\u0441\u0435\u043b \u043e\u0442 1 \u0434\u043e 1000000. \u0420\u0430\u0437\u0434\u0435\u043b\u0438\u0442\u0435 \u0432\u044b\u0447\u0438\u0441\u043b\u0435\u043d\u0438\u044f \u043d\u0430 \u043d\u0435\u0441\u043a\u043e\u043b\u044c\u043a\u043e \u043f\u0430\u0440\u0430\u043b\u043b\u0435\u043b\u044c\u043d\u044b\u0445 \u0437\u0430\u0434\u0430\u0447 \u0434\u043b\u044f \u0443\u0441\u043a\u043e\u0440\u0435\u043d\u0438\u044f \u0432\u044b\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u044f.","title":"\u041e\u043f\u0438\u0441\u0430\u043d\u0438\u0435"},{"location":"task1/#async","text":"import asyncio import time async def calculate_partial_sum(start, end): partial_sum = sum(range(start, end)) return partial_sum async def calculate_sum(): num_tasks = 5 chunk_size = 1000000 // num_tasks tasks = [] start_time = time.time() for i in range(num_tasks): start = i * chunk_size + 1 end = (i + 1) * chunk_size + 1 if i < num_tasks - 1 else 1000001 task = asyncio.create_task(calculate_partial_sum(start, end)) tasks.append(task) partial_sums = await asyncio.gather(*tasks) total_sum = sum(partial_sums) end_time = time.time() print(\"Total sum (Async):\", total_sum) print(\"Time taken:\", end_time - start_time, \"seconds\") if __name__ == \"__main__\": asyncio.run(calculate_sum())","title":"Async"},{"location":"task1/#multiprocessing","text":"import multiprocessing import time def calculate_partial_sum(start, end, result): partial_sum = sum(range(start, end)) result.put(partial_sum) def calculate_sum(): num_processes = 2 results = multiprocessing.Queue() processes = [] start_time = time.time() chunk_size = 1000000 // num_processes for i in range(num_processes): start = i * chunk_size + 1 end = (i + 1) * chunk_size + 1 if i < num_processes - 1 else 1000001 process = multiprocessing.Process(target=calculate_partial_sum, args=(start, end, results)) processes.append(process) process.start() for process in processes: process.join() end_time = time.time() total_sum = 0 while not results.empty(): total_sum += results.get() print(\"Total sum (Multiprocessing):\", total_sum) print(\"Time taken:\", end_time - start_time, \"seconds\") if __name__ == \"__main__\": calculate_sum()","title":"Multiprocessing"},{"location":"task1/#threading","text":"import threading import time def calculate_partial_sum(start, end, result): partial_sum = sum(range(start, end)) result.append(partial_sum) def calculate_sum(): num_threads = 4 results = [] start_time = time.time() threads = [] chunk_size = 1000000 // num_threads for i in range(num_threads): start = i * chunk_size + 1 end = (i + 1) * chunk_size + 1 if i < num_threads - 1 else 1000001 thread = threading.Thread(target=calculate_partial_sum, args=(start, end, results)) threads.append(thread) thread.start() for thread in threads: thread.join() end_time = time.time() total_sum = sum(results) print(\"Total sum (Threading):\", total_sum) print(\"Time taken:\", end_time - start_time, \"seconds\") if __name__ == \"__main__\": calculate_sum()","title":"Threading"},{"location":"task1/#_2","text":"\u041f\u043e \u0432\u0440\u0435\u043c\u0435\u043d\u0438 \u0432\u044b\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u044f \u0441\u0438\u043b\u044c\u043d\u043e \u043f\u0440\u043e\u0438\u0433\u0440\u044b\u0432\u0430\u0435\u0442 multiprocessing (\u0438\u0437-\u0437\u0430 \u043f\u043e\u0442\u0440\u0430\u0447\u0435\u043d\u043d\u043e\u0433\u043e \u043d\u0430 \u0441\u043e\u0437\u0434\u0430\u043d\u0438\u0435 \u043f\u043e\u0442\u043e\u043a\u043e\u0432 \u0440\u0435\u0441\u0443\u0440\u0441\u043e\u0432), async \u0438 threading \u043e\u0442\u0440\u0430\u0431\u043e\u0442\u0430\u043b\u0438 \u043f\u043e\u0447\u0442\u0438 \u043e\u0434\u0438\u043d\u0430\u043a\u043e\u0432\u043e.","title":"\u0420\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u044b"},{"location":"task2/","text":"Task 2 \u041e\u043f\u0438\u0441\u0430\u043d\u0438\u0435 \u041d\u0430\u043f\u0438\u0448\u0438\u0442\u0435 \u043f\u0440\u043e\u0433\u0440\u0430\u043c\u043c\u0443 \u043d\u0430 Python \u0434\u043b\u044f \u043f\u0430\u0440\u0430\u043b\u043b\u0435\u043b\u044c\u043d\u043e\u0433\u043e \u043f\u0430\u0440\u0441\u0438\u043d\u0433\u0430 \u043d\u0435\u0441\u043a\u043e\u043b\u044c\u043a\u0438\u0445 \u0432\u0435\u0431-\u0441\u0442\u0440\u0430\u043d\u0438\u0446 \u0441 \u0441\u043e\u0445\u0440\u0430\u043d\u0435\u043d\u0438\u0435\u043c \u0434\u0430\u043d\u043d\u044b\u0445 \u0432 \u0431\u0430\u0437\u0443 \u0434\u0430\u043d\u043d\u044b\u0445 \u0441 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043d\u0438\u0435\u043c \u043f\u043e\u0434\u0445\u043e\u0434\u043e\u0432 threading, multiprocessing \u0438 async. Models import datetime from typing import Optional, List from pydantic import validator, EmailStr from sqlmodel import SQLModel, Field, Relationship, AutoString from enum import Enum class ExchangeStatus(Enum): agreed = \"agreed\" rejected = \"rejected\" notselected = \"not selected\" # book instance class BookInstanceBase(SQLModel): book_id: Optional[int] = Field(default=None, foreign_key=\"book.id\") date: datetime.datetime publisher: str features: str class BookInstance(BookInstanceBase, table=True): id: int = Field(default=None, primary_key=True) owner_id: Optional[int] = Field(default=None, foreign_key=\"user.id\") requests: Optional[List[\"BookExchange\"]] = Relationship( back_populates=\"book_instance\", sa_relationship_kwargs=dict(foreign_keys=\"[BookExchange.book_instance_id]\"), ) book: Optional[\"Book\"] = Relationship(back_populates=\"instances\") owner: Optional[\"User\"] = Relationship(back_populates=\"instances\") class BookInstanceRead(BookInstanceBase): id: int owner_id: int class BookInstanceWithBook(BookInstanceRead): book: \"BookRead\" = None class BookInstanceReadFull(BookInstanceWithBook): requests: list[\"BookExchangeRead\"] = [] owner: \"UserBase\" = None # author class AuthorBase(SQLModel): name: str bio: str class Author(AuthorBase, table=True): id: int = Field(default=None, primary_key=True) books: Optional[List[\"Book\"]] = Relationship(back_populates=\"author\") class AuthorRead(AuthorBase): id: int class AuthorReadFull(AuthorRead): books: list[\"BookRead\"] = [] # book class BookBase(SQLModel): title: str description: str author_id: Optional[int] = Field(default=None, foreign_key=\"author.id\") class Book(BookBase, table=True): id: int = Field(default=None, primary_key=True) author: Optional[Author] = Relationship(back_populates=\"books\") owners: Optional[List[\"User\"]] = Relationship(back_populates=\"books\", link_model=BookInstance) instances: Optional[List[\"BookInstance\"]] = Relationship(back_populates=\"book\") class BookRead(BookBase): id: int class BookReadFull(BookRead): author: AuthorRead = None owners: list[\"UserBase\"] = [] instances: list[\"BookInstanceRead\"] = [] # user class UserBase(SQLModel): id: int = Field(primary_key=True) username: str = Field(index=True) name: str about: str email: EmailStr = Field(unique=True, index=True, sa_type=AutoString) class User(UserBase, table=True): password: str = Field(max_length=256, min_length=6) created_at: datetime.datetime = datetime.datetime.now() books: Optional[List[\"Book\"]] = Relationship(back_populates=\"owners\", link_model=BookInstance) sender_requests: Optional[List[\"BookExchange\"]] = Relationship( back_populates=\"sender\", sa_relationship_kwargs=dict(foreign_keys=\"[BookExchange.sender_id]\"), ) receiver_requests: Optional[List[\"BookExchange\"]] = Relationship( back_populates=\"receiver\", sa_relationship_kwargs=dict(foreign_keys=\"[BookExchange.receiver_id]\"), ) instances: Optional[List[\"BookInstance\"]] = Relationship(back_populates=\"owner\") class UserReadFull(UserBase): sender_requests: list[\"BookExchangeRead\"] = [] receiver_requests: list[\"BookExchangeRead\"] = [] instances: list[\"BookInstanceWithBook\"] = [] class UserInput(SQLModel): name: str about: str username: str password: str = Field(max_length=256, min_length=6) password2: str email: EmailStr = Field(unique=True, index=True, sa_type=AutoString) @validator('password2') def password_match(cls, v, values, **kwargs): if 'password' in values and v != values['password']: raise ValueError('passwords don\\'t match') return v class UserLogin(SQLModel): username: str password: str class UserPassword(SQLModel): old_password: str new_password: str # book exchange class BookExchangeBase(SQLModel): book_instance_id: Optional[int] = Field(default=None, foreign_key=\"bookinstance.id\") status: ExchangeStatus date_start: datetime.datetime date_end: datetime.datetime class BookExchange(BookExchangeBase, table=True): id: int = Field(default=None, primary_key=True) sender_id: Optional[int] = Field(default=None, foreign_key=\"user.id\") receiver_id: Optional[int] = Field(default=None, foreign_key=\"user.id\") sender: Optional[\"User\"] = Relationship( back_populates=\"sender_requests\", sa_relationship_kwargs=dict(foreign_keys=\"[BookExchange.sender_id]\"), ) receiver: Optional[\"User\"] = Relationship( back_populates=\"receiver_requests\", sa_relationship_kwargs=dict(foreign_keys=\"[BookExchange.receiver_id]\"), ) book_instance: Optional[\"BookInstance\"] = Relationship( back_populates=\"requests\", sa_relationship_kwargs=dict(foreign_keys=\"[BookExchange.book_instance_id]\"), ) class BookExchangeChangeStatus(SQLModel): status: ExchangeStatus class BookExchangeRead(BookExchangeBase): id: int sender_id: int receiver_id: int class BookExchangeReadFull(BookExchangeRead): sender: \"UserBase\" = None receiver: \"UserBase\" = None book_instance: \"BookInstanceWithBook\" = None \u0424\u0443\u043d\u043a\u0446\u0438\u0438 \u0434\u043b\u044f \u043f\u0430\u0440\u0441\u0438\u043d\u0433\u0430 def parse_author_info(url): # \u041e\u0442\u043f\u0440\u0430\u0432\u043b\u044f\u0435\u043c GET-\u0437\u0430\u043f\u0440\u043e\u0441 \u043a \u0432\u0435\u0431-\u0441\u0442\u0440\u0430\u043d\u0438\u0446\u0435 response = requests.get(url) # \u0421\u043e\u0437\u0434\u0430\u0435\u043c \u043e\u0431\u044a\u0435\u043a\u0442 BeautifulSoup \u0434\u043b\u044f \u043f\u0430\u0440\u0441\u0438\u043d\u0433\u0430 \u0441\u043e\u0434\u0435\u0440\u0436\u0438\u043c\u043e\u0433\u043e \u0441\u0442\u0440\u0430\u043d\u0438\u0446\u044b soup = BeautifulSoup(response.text, 'html.parser') # \u0418\u0437\u0432\u043b\u0435\u043a\u0430\u0435\u043c \u0438\u043c\u044f \u0430\u0432\u0442\u043e\u0440\u0430 author_name = soup.find('h1', class_='Author_authorName__i4Wxb').text.strip() # \u0418\u0437\u0432\u043b\u0435\u043a\u0430\u0435\u043c \u0441\u043f\u0438\u0441\u043e\u043a \u043a\u043d\u0438\u0433 books_elements = soup.find_all('p', class_='ArtInfoTile_title__TCqN1') books = [book.text.strip() for book in books_elements] # \u0424\u043e\u0440\u043c\u0438\u0440\u0443\u0435\u043c \u0441\u043b\u043e\u0432\u0430\u0440\u044c \u0441 \u0434\u0430\u043d\u043d\u044b\u043c\u0438 \u043e\u0431 \u0430\u0432\u0442\u043e\u0440\u0435 \u0438 \u0435\u0433\u043e \u043a\u043d\u0438\u0433\u0430\u0445 author_data = { 'author_name': author_name, 'books': books } # \u041f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u0443\u0435\u043c \u0441\u043b\u043e\u0432\u0430\u0440\u044c \u0432 JSON json_data = json.dumps(author_data, ensure_ascii=False) return json_data async def parse_author_info(url): async with aiohttp.ClientSession(connector=aiohttp.TCPConnector(ssl=False)) as session: html = await fetch(session, url) soup = BeautifulSoup(html, 'html.parser') author_name = soup.find('h1', class_='Author_authorName__i4Wxb').text.strip() books_elements = soup.find_all('p', class_='ArtInfoTile_title__TCqN1') books = [book.text.strip() for book in books_elements] author_data = { 'author_name': author_name, 'books': books } json_data = json.dumps(author_data, ensure_ascii=False) return json_data \u0424\u0443\u043d\u043a\u0446\u0438\u0438 \u0434\u043b\u044f \u0441\u043e\u0445\u0440\u0430\u043d\u0435\u043d\u0438\u044f \u0434\u0430\u043d\u043d\u044b\u0445 \u0432 \u0431\u0434 def save_author_and_books_from_json(data: str): # \u0414\u0435\u043a\u043e\u0434\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u0435 JSON-\u0434\u0430\u043d\u043d\u044b\u0445 data_dict = json.loads(data) # \u0421\u043e\u0437\u0434\u0430\u043d\u0438\u0435 \u0441\u0435\u0441\u0441\u0438\u0438 session = SessionLocal() try: # \u0418\u0437\u0432\u043b\u0435\u0447\u0435\u043d\u0438\u0435 \u0434\u0430\u043d\u043d\u044b\u0445 \u043e\u0431 \u0430\u0432\u0442\u043e\u0440\u0435 \u0438\u0437 JSON author_name = data_dict.get('author_name') if not author_name: raise ValueError(\"\u041d\u0435\u0434\u043e\u0441\u0442\u0430\u0442\u043e\u0447\u043d\u043e \u0434\u0430\u043d\u043d\u044b\u0445 \u0434\u043b\u044f \u0441\u043e\u0445\u0440\u0430\u043d\u0435\u043d\u0438\u044f.\") # \u0421\u043e\u0437\u0434\u0430\u043d\u0438\u0435 \u043e\u0431\u044a\u0435\u043a\u0442\u0430 Author author = Author(name=author_name, bio=\"\") # \u0418\u0437\u0432\u043b\u0435\u0447\u0435\u043d\u0438\u0435 \u0441\u043f\u0438\u0441\u043a\u0430 \u043a\u043d\u0438\u0433 \u0438\u0437 JSON book_titles = data_dict.get('books') if not book_titles: raise ValueError(\"\u041d\u0435 \u0443\u043a\u0430\u0437\u0430\u043d \u0441\u043f\u0438\u0441\u043e\u043a \u043a\u043d\u0438\u0433 \u0434\u043b\u044f \u0441\u043e\u0445\u0440\u0430\u043d\u0435\u043d\u0438\u044f.\") # \u0421\u043e\u0437\u0434\u0430\u043d\u0438\u0435 \u043e\u0431\u044a\u0435\u043a\u0442\u043e\u0432 Book \u0438 \u0438\u0445 \u0434\u043e\u0431\u0430\u0432\u043b\u0435\u043d\u0438\u0435 \u043a \u0430\u0432\u0442\u043e\u0440\u0443 books = [Book(title=title, description=\"\", author=author) for title in book_titles] # \u0414\u043e\u0431\u0430\u0432\u043b\u0435\u043d\u0438\u0435 \u043e\u0431\u044a\u0435\u043a\u0442\u043e\u0432 \u0432 \u0441\u0435\u0441\u0441\u0438\u044e session.add(author) session.add_all(books) # \u0421\u043e\u0445\u0440\u0430\u043d\u0435\u043d\u0438\u0435 \u0438\u0437\u043c\u0435\u043d\u0435\u043d\u0438\u0439 session.commit() session.refresh(author) return author, books finally: # \u0417\u0430\u043a\u0440\u044b\u0442\u0438\u0435 \u0441\u0435\u0441\u0441\u0438\u0438 session.close() async def save_author_and_books_from_json(data: str): # \u0414\u0435\u043a\u043e\u0434\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u0435 JSON-\u0434\u0430\u043d\u043d\u044b\u0445 data_dict = json.loads(data) # \u0421\u043e\u0437\u0434\u0430\u043d\u0438\u0435 \u0430\u0441\u0438\u043d\u0445\u0440\u043e\u043d\u043d\u043e\u0439 \u0441\u0435\u0441\u0441\u0438\u0438 async with AsyncSession(engine) as session: # \u0418\u0437\u0432\u043b\u0435\u0447\u0435\u043d\u0438\u0435 \u0434\u0430\u043d\u043d\u044b\u0445 \u043e\u0431 \u0430\u0432\u0442\u043e\u0440\u0435 \u0438\u0437 JSON author_name = data_dict.get('author_name') if not author_name: raise ValueError(\"\u041d\u0435\u0434\u043e\u0441\u0442\u0430\u0442\u043e\u0447\u043d\u043e \u0434\u0430\u043d\u043d\u044b\u0445 \u0434\u043b\u044f \u0441\u043e\u0445\u0440\u0430\u043d\u0435\u043d\u0438\u044f.\") # \u0421\u043e\u0437\u0434\u0430\u043d\u0438\u0435 \u043e\u0431\u044a\u0435\u043a\u0442\u0430 Author author = Author(name=author_name, bio=\"\") # \u0418\u0437\u0432\u043b\u0435\u0447\u0435\u043d\u0438\u0435 \u0441\u043f\u0438\u0441\u043a\u0430 \u043a\u043d\u0438\u0433 \u0438\u0437 JSON book_titles = data_dict.get('books') if not book_titles: raise ValueError(\"\u041d\u0435 \u0443\u043a\u0430\u0437\u0430\u043d \u0441\u043f\u0438\u0441\u043e\u043a \u043a\u043d\u0438\u0433 \u0434\u043b\u044f \u0441\u043e\u0445\u0440\u0430\u043d\u0435\u043d\u0438\u044f.\") # \u0421\u043e\u0437\u0434\u0430\u043d\u0438\u0435 \u043e\u0431\u044a\u0435\u043a\u0442\u043e\u0432 Book \u0438 \u0438\u0445 \u0434\u043e\u0431\u0430\u0432\u043b\u0435\u043d\u0438\u0435 \u043a \u0430\u0432\u0442\u043e\u0440\u0443 books = [Book(title=title, description=\"\", author=author) for title in book_titles] # \u0414\u043e\u0431\u0430\u0432\u043b\u0435\u043d\u0438\u0435 \u043e\u0431\u044a\u0435\u043a\u0442\u043e\u0432 \u0432 \u0441\u0435\u0441\u0441\u0438\u044e session.add(author) session.add_all(books) # \u0421\u043e\u0445\u0440\u0430\u043d\u0435\u043d\u0438\u0435 \u0438\u0437\u043c\u0435\u043d\u0435\u043d\u0438\u0439 await session.commit() # \u0417\u0430\u043f\u0440\u043e\u0441 \u043d\u0430 \u043f\u043e\u043b\u0443\u0447\u0435\u043d\u0438\u0435 \u0441\u043e\u0445\u0440\u0430\u043d\u0435\u043d\u043d\u043e\u0433\u043e \u0430\u0432\u0442\u043e\u0440\u0430 await session.refresh(author) return author, books Async import asyncio import aiohttp import json from save_data_async import save_author_and_books_from_json from async_parser import parse_author_info import time # \u0421\u043f\u0438\u0441\u043e\u043a URL-\u0430\u0434\u0440\u0435\u0441\u043e\u0432 \u0434\u043b\u044f \u043f\u0430\u0440\u0441\u0438\u043d\u0433\u0430 urls = [\"https://www.litres.ru/author/patrik-king/\", \"https://www.litres.ru/author/vladimir-pozner/\", \"https://www.litres.ru/author/allan-dib/\"] async def parse_and_save(url): author_info = await parse_author_info(url) await save_author_and_books_from_json(author_info) async def main(): start_time = time.time() tasks = [] for url in urls: task = asyncio.create_task(parse_and_save(url)) tasks.append(task) await asyncio.gather(*tasks) end_time = time.time() print(f\"\u0412\u0440\u0435\u043c\u044f \u0432\u044b\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u044f: {end_time - start_time} \u0441\u0435\u043a\u0443\u043d\u0434\") if __name__ == \"__main__\": asyncio.run(main()) Multiprocessing import multiprocessing from parser import parse_author_info from save_data import save_author_and_books_from_json import time # \u0421\u043f\u0438\u0441\u043e\u043a URL-\u0430\u0434\u0440\u0435\u0441\u043e\u0432 \u0434\u043b\u044f \u043f\u0430\u0440\u0441\u0438\u043d\u0433\u0430 urls = [ \"https://www.litres.ru/author/patrik-king/\", \"https://www.litres.ru/author/vladimir-pozner/\", \"https://www.litres.ru/author/allan-dib/\" ] # \u0424\u0443\u043d\u043a\u0446\u0438\u044f \u0434\u043b\u044f \u043f\u0430\u0440\u0430\u043b\u043b\u0435\u043b\u044c\u043d\u043e\u0433\u043e \u043f\u0430\u0440\u0441\u0438\u043d\u0433\u0430 \u0438 \u0441\u043e\u0445\u0440\u0430\u043d\u0435\u043d\u0438\u044f \u0434\u0430\u043d\u043d\u044b\u0445 def parallel_parse_and_save(chunk): for url in chunk: author_info = parse_author_info(url) save_author_and_books_from_json(author_info) # \u0424\u0443\u043d\u043a\u0446\u0438\u044f \u0434\u043b\u044f \u0437\u0430\u0441\u0435\u0447\u0435\u043d\u0438\u044f \u0432\u0440\u0435\u043c\u0435\u043d\u0438 \u0438\u0441\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u044f \u0438 \u0437\u0430\u043f\u0443\u0441\u043a\u0430 \u043f\u0430\u0440\u0441\u0438\u043d\u0433\u0430 def measure_execution_time(): start_time = time.time() # \u0420\u0430\u0437\u0434\u0435\u043b\u0435\u043d\u0438\u0435 \u0441\u043f\u0438\u0441\u043a\u0430 URL-\u0430\u0434\u0440\u0435\u0441\u043e\u0432 \u043d\u0430 \u0440\u0430\u0432\u043d\u044b\u0435 \u0447\u0430\u0441\u0442\u0438 (chunks) num_processes = len(urls) chunk_size = len(urls) // num_processes chunks = [urls[i:i+chunk_size] for i in range(0, len(urls), chunk_size)] # \u0421\u043e\u0437\u0434\u0430\u043d\u0438\u0435 \u043f\u0440\u043e\u0446\u0435\u0441\u0441\u043e\u0432 \u0434\u043b\u044f \u043f\u0430\u0440\u0430\u043b\u043b\u0435\u043b\u044c\u043d\u043e\u0433\u043e \u043f\u0430\u0440\u0441\u0438\u043d\u0433\u0430 processes = [] for chunk in chunks: process = multiprocessing.Process(target=parallel_parse_and_save, args=(chunk,)) processes.append(process) process.start() # \u041e\u0436\u0438\u0434\u0430\u043d\u0438\u0435 \u0437\u0430\u0432\u0435\u0440\u0448\u0435\u043d\u0438\u044f \u0432\u0441\u0435\u0445 \u043f\u0440\u043e\u0446\u0435\u0441\u0441\u043e\u0432 for process in processes: process.join() end_time = time.time() execution_time = end_time - start_time print(f\"Execution time: {execution_time} seconds\") if __name__ == '__main__': # \u0412\u044b\u0437\u043e\u0432 \u0444\u0443\u043d\u043a\u0446\u0438\u0438 \u0434\u043b\u044f \u0437\u0430\u0441\u0435\u0447\u0435\u043d\u0438\u044f \u0432\u0440\u0435\u043c\u0435\u043d\u0438 \u0438\u0441\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u044f \u0438 \u0437\u0430\u043f\u0443\u0441\u043a\u0430 \u043f\u0430\u0440\u0441\u0438\u043d\u0433\u0430 measure_execution_time() Threading import threading from parser import parse_author_info from save_data import save_author_and_books_from_json import time # \u0421\u043f\u0438\u0441\u043e\u043a URL-\u0430\u0434\u0440\u0435\u0441\u043e\u0432 \u0434\u043b\u044f \u043f\u0430\u0440\u0441\u0438\u043d\u0433\u0430 urls = [ \"https://www.litres.ru/author/patrik-king/\", \"https://www.litres.ru/author/vladimir-pozner/\", \"https://www.litres.ru/author/allan-dib/\" ] # \u0424\u0443\u043d\u043a\u0446\u0438\u044f \u0434\u043b\u044f \u043f\u0430\u0440\u0430\u043b\u043b\u0435\u043b\u044c\u043d\u043e\u0433\u043e \u043f\u0430\u0440\u0441\u0438\u043d\u0433\u0430 \u0438 \u0441\u043e\u0445\u0440\u0430\u043d\u0435\u043d\u0438\u044f \u0434\u0430\u043d\u043d\u044b\u0445 def parallel_parse_and_save(urls): for url in urls: author_info = parse_author_info(url) save_author_and_books_from_json(author_info) # \u0424\u0443\u043d\u043a\u0446\u0438\u044f \u0434\u043b\u044f \u0437\u0430\u0441\u0435\u0447\u0435\u043d\u0438\u044f \u0432\u0440\u0435\u043c\u0435\u043d\u0438 \u0438\u0441\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u044f \u0438 \u0437\u0430\u043f\u0443\u0441\u043a\u0430 \u043f\u0430\u0440\u0441\u0438\u043d\u0433\u0430 def measure_execution_time(): start_time = time.time() # \u0420\u0430\u0437\u0434\u0435\u043b\u0435\u043d\u0438\u0435 \u0441\u043f\u0438\u0441\u043a\u0430 URL-\u0430\u0434\u0440\u0435\u0441\u043e\u0432 \u043d\u0430 \u0440\u0430\u0432\u043d\u044b\u0435 \u0447\u0430\u0441\u0442\u0438 num_threads = 3 chunk_size = len(urls) // num_threads chunks = [urls[i:i + chunk_size] for i in range(0, len(urls), chunk_size)] # \u0417\u0430\u043f\u0443\u0441\u043a \u043f\u0430\u0440\u0430\u043b\u043b\u0435\u043b\u044c\u043d\u043e\u0433\u043e \u043f\u0430\u0440\u0441\u0438\u043d\u0433\u0430 \u0434\u043b\u044f \u043a\u0430\u0436\u0434\u043e\u0439 \u0447\u0430\u0441\u0442\u0438 threads = [] for chunk in chunks: thread = threading.Thread(target=parallel_parse_and_save, args=(chunk,)) thread.start() threads.append(thread) # \u041e\u0436\u0438\u0434\u0430\u043d\u0438\u0435 \u0437\u0430\u0432\u0435\u0440\u0448\u0435\u043d\u0438\u044f \u0432\u0441\u0435\u0445 \u043f\u043e\u0442\u043e\u043a\u043e\u0432 for thread in threads: thread.join() end_time = time.time() execution_time = end_time - start_time print(f\"Execution time: {execution_time} seconds\") # \u0412\u044b\u0437\u043e\u0432 \u0444\u0443\u043d\u043a\u0446\u0438\u0438 \u0434\u043b\u044f \u0437\u0430\u0441\u0435\u0447\u0435\u043d\u0438\u044f \u0432\u0440\u0435\u043c\u0435\u043d\u0438 \u0438\u0441\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u044f \u0438 \u0437\u0430\u043f\u0443\u0441\u043a\u0430 \u043f\u0430\u0440\u0441\u0438\u043d\u0433\u0430 measure_execution_time() \u0420\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u044b \u0420\u0430\u0441\u0445\u043e\u0434 \u0440\u0435\u0441\u0443\u0440\u0441\u043e\u0432 \u043d\u0430 \u043c\u0443\u043b\u044c\u0442\u0438\u043f\u0440\u043e\u0446\u0435\u0441\u0441\u0438\u043d\u0433 \u043d\u0435 \u043e\u043f\u0440\u0430\u0432\u0434\u0430\u043d, \u043f\u043e\u044d\u0442\u043e\u043c\u0443 \u043e\u043d \u043e\u0442\u0440\u0430\u0431\u0430\u0442\u044b\u0432\u0435\u0442 \u0434\u043e\u043b\u044c\u0448\u0435. Async and threading \u043e\u0442\u0440\u0430\u0431\u0430\u0442\u044b\u0432\u0430\u044e\u0442 \u043f\u0440\u0438\u043c\u0435\u0440\u043d\u043e \u043e\u0434\u0438\u043d\u0430\u043a\u043e\u0432\u043e.","title":"Task 2"},{"location":"task2/#task-2","text":"","title":"Task 2"},{"location":"task2/#_1","text":"\u041d\u0430\u043f\u0438\u0448\u0438\u0442\u0435 \u043f\u0440\u043e\u0433\u0440\u0430\u043c\u043c\u0443 \u043d\u0430 Python \u0434\u043b\u044f \u043f\u0430\u0440\u0430\u043b\u043b\u0435\u043b\u044c\u043d\u043e\u0433\u043e \u043f\u0430\u0440\u0441\u0438\u043d\u0433\u0430 \u043d\u0435\u0441\u043a\u043e\u043b\u044c\u043a\u0438\u0445 \u0432\u0435\u0431-\u0441\u0442\u0440\u0430\u043d\u0438\u0446 \u0441 \u0441\u043e\u0445\u0440\u0430\u043d\u0435\u043d\u0438\u0435\u043c \u0434\u0430\u043d\u043d\u044b\u0445 \u0432 \u0431\u0430\u0437\u0443 \u0434\u0430\u043d\u043d\u044b\u0445 \u0441 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043d\u0438\u0435\u043c \u043f\u043e\u0434\u0445\u043e\u0434\u043e\u0432 threading, multiprocessing \u0438 async.","title":"\u041e\u043f\u0438\u0441\u0430\u043d\u0438\u0435"},{"location":"task2/#models","text":"import datetime from typing import Optional, List from pydantic import validator, EmailStr from sqlmodel import SQLModel, Field, Relationship, AutoString from enum import Enum class ExchangeStatus(Enum): agreed = \"agreed\" rejected = \"rejected\" notselected = \"not selected\" # book instance class BookInstanceBase(SQLModel): book_id: Optional[int] = Field(default=None, foreign_key=\"book.id\") date: datetime.datetime publisher: str features: str class BookInstance(BookInstanceBase, table=True): id: int = Field(default=None, primary_key=True) owner_id: Optional[int] = Field(default=None, foreign_key=\"user.id\") requests: Optional[List[\"BookExchange\"]] = Relationship( back_populates=\"book_instance\", sa_relationship_kwargs=dict(foreign_keys=\"[BookExchange.book_instance_id]\"), ) book: Optional[\"Book\"] = Relationship(back_populates=\"instances\") owner: Optional[\"User\"] = Relationship(back_populates=\"instances\") class BookInstanceRead(BookInstanceBase): id: int owner_id: int class BookInstanceWithBook(BookInstanceRead): book: \"BookRead\" = None class BookInstanceReadFull(BookInstanceWithBook): requests: list[\"BookExchangeRead\"] = [] owner: \"UserBase\" = None # author class AuthorBase(SQLModel): name: str bio: str class Author(AuthorBase, table=True): id: int = Field(default=None, primary_key=True) books: Optional[List[\"Book\"]] = Relationship(back_populates=\"author\") class AuthorRead(AuthorBase): id: int class AuthorReadFull(AuthorRead): books: list[\"BookRead\"] = [] # book class BookBase(SQLModel): title: str description: str author_id: Optional[int] = Field(default=None, foreign_key=\"author.id\") class Book(BookBase, table=True): id: int = Field(default=None, primary_key=True) author: Optional[Author] = Relationship(back_populates=\"books\") owners: Optional[List[\"User\"]] = Relationship(back_populates=\"books\", link_model=BookInstance) instances: Optional[List[\"BookInstance\"]] = Relationship(back_populates=\"book\") class BookRead(BookBase): id: int class BookReadFull(BookRead): author: AuthorRead = None owners: list[\"UserBase\"] = [] instances: list[\"BookInstanceRead\"] = [] # user class UserBase(SQLModel): id: int = Field(primary_key=True) username: str = Field(index=True) name: str about: str email: EmailStr = Field(unique=True, index=True, sa_type=AutoString) class User(UserBase, table=True): password: str = Field(max_length=256, min_length=6) created_at: datetime.datetime = datetime.datetime.now() books: Optional[List[\"Book\"]] = Relationship(back_populates=\"owners\", link_model=BookInstance) sender_requests: Optional[List[\"BookExchange\"]] = Relationship( back_populates=\"sender\", sa_relationship_kwargs=dict(foreign_keys=\"[BookExchange.sender_id]\"), ) receiver_requests: Optional[List[\"BookExchange\"]] = Relationship( back_populates=\"receiver\", sa_relationship_kwargs=dict(foreign_keys=\"[BookExchange.receiver_id]\"), ) instances: Optional[List[\"BookInstance\"]] = Relationship(back_populates=\"owner\") class UserReadFull(UserBase): sender_requests: list[\"BookExchangeRead\"] = [] receiver_requests: list[\"BookExchangeRead\"] = [] instances: list[\"BookInstanceWithBook\"] = [] class UserInput(SQLModel): name: str about: str username: str password: str = Field(max_length=256, min_length=6) password2: str email: EmailStr = Field(unique=True, index=True, sa_type=AutoString) @validator('password2') def password_match(cls, v, values, **kwargs): if 'password' in values and v != values['password']: raise ValueError('passwords don\\'t match') return v class UserLogin(SQLModel): username: str password: str class UserPassword(SQLModel): old_password: str new_password: str # book exchange class BookExchangeBase(SQLModel): book_instance_id: Optional[int] = Field(default=None, foreign_key=\"bookinstance.id\") status: ExchangeStatus date_start: datetime.datetime date_end: datetime.datetime class BookExchange(BookExchangeBase, table=True): id: int = Field(default=None, primary_key=True) sender_id: Optional[int] = Field(default=None, foreign_key=\"user.id\") receiver_id: Optional[int] = Field(default=None, foreign_key=\"user.id\") sender: Optional[\"User\"] = Relationship( back_populates=\"sender_requests\", sa_relationship_kwargs=dict(foreign_keys=\"[BookExchange.sender_id]\"), ) receiver: Optional[\"User\"] = Relationship( back_populates=\"receiver_requests\", sa_relationship_kwargs=dict(foreign_keys=\"[BookExchange.receiver_id]\"), ) book_instance: Optional[\"BookInstance\"] = Relationship( back_populates=\"requests\", sa_relationship_kwargs=dict(foreign_keys=\"[BookExchange.book_instance_id]\"), ) class BookExchangeChangeStatus(SQLModel): status: ExchangeStatus class BookExchangeRead(BookExchangeBase): id: int sender_id: int receiver_id: int class BookExchangeReadFull(BookExchangeRead): sender: \"UserBase\" = None receiver: \"UserBase\" = None book_instance: \"BookInstanceWithBook\" = None","title":"Models"},{"location":"task2/#_2","text":"def parse_author_info(url): # \u041e\u0442\u043f\u0440\u0430\u0432\u043b\u044f\u0435\u043c GET-\u0437\u0430\u043f\u0440\u043e\u0441 \u043a \u0432\u0435\u0431-\u0441\u0442\u0440\u0430\u043d\u0438\u0446\u0435 response = requests.get(url) # \u0421\u043e\u0437\u0434\u0430\u0435\u043c \u043e\u0431\u044a\u0435\u043a\u0442 BeautifulSoup \u0434\u043b\u044f \u043f\u0430\u0440\u0441\u0438\u043d\u0433\u0430 \u0441\u043e\u0434\u0435\u0440\u0436\u0438\u043c\u043e\u0433\u043e \u0441\u0442\u0440\u0430\u043d\u0438\u0446\u044b soup = BeautifulSoup(response.text, 'html.parser') # \u0418\u0437\u0432\u043b\u0435\u043a\u0430\u0435\u043c \u0438\u043c\u044f \u0430\u0432\u0442\u043e\u0440\u0430 author_name = soup.find('h1', class_='Author_authorName__i4Wxb').text.strip() # \u0418\u0437\u0432\u043b\u0435\u043a\u0430\u0435\u043c \u0441\u043f\u0438\u0441\u043e\u043a \u043a\u043d\u0438\u0433 books_elements = soup.find_all('p', class_='ArtInfoTile_title__TCqN1') books = [book.text.strip() for book in books_elements] # \u0424\u043e\u0440\u043c\u0438\u0440\u0443\u0435\u043c \u0441\u043b\u043e\u0432\u0430\u0440\u044c \u0441 \u0434\u0430\u043d\u043d\u044b\u043c\u0438 \u043e\u0431 \u0430\u0432\u0442\u043e\u0440\u0435 \u0438 \u0435\u0433\u043e \u043a\u043d\u0438\u0433\u0430\u0445 author_data = { 'author_name': author_name, 'books': books } # \u041f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u0443\u0435\u043c \u0441\u043b\u043e\u0432\u0430\u0440\u044c \u0432 JSON json_data = json.dumps(author_data, ensure_ascii=False) return json_data async def parse_author_info(url): async with aiohttp.ClientSession(connector=aiohttp.TCPConnector(ssl=False)) as session: html = await fetch(session, url) soup = BeautifulSoup(html, 'html.parser') author_name = soup.find('h1', class_='Author_authorName__i4Wxb').text.strip() books_elements = soup.find_all('p', class_='ArtInfoTile_title__TCqN1') books = [book.text.strip() for book in books_elements] author_data = { 'author_name': author_name, 'books': books } json_data = json.dumps(author_data, ensure_ascii=False) return json_data","title":"\u0424\u0443\u043d\u043a\u0446\u0438\u0438 \u0434\u043b\u044f \u043f\u0430\u0440\u0441\u0438\u043d\u0433\u0430"},{"location":"task2/#_3","text":"def save_author_and_books_from_json(data: str): # \u0414\u0435\u043a\u043e\u0434\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u0435 JSON-\u0434\u0430\u043d\u043d\u044b\u0445 data_dict = json.loads(data) # \u0421\u043e\u0437\u0434\u0430\u043d\u0438\u0435 \u0441\u0435\u0441\u0441\u0438\u0438 session = SessionLocal() try: # \u0418\u0437\u0432\u043b\u0435\u0447\u0435\u043d\u0438\u0435 \u0434\u0430\u043d\u043d\u044b\u0445 \u043e\u0431 \u0430\u0432\u0442\u043e\u0440\u0435 \u0438\u0437 JSON author_name = data_dict.get('author_name') if not author_name: raise ValueError(\"\u041d\u0435\u0434\u043e\u0441\u0442\u0430\u0442\u043e\u0447\u043d\u043e \u0434\u0430\u043d\u043d\u044b\u0445 \u0434\u043b\u044f \u0441\u043e\u0445\u0440\u0430\u043d\u0435\u043d\u0438\u044f.\") # \u0421\u043e\u0437\u0434\u0430\u043d\u0438\u0435 \u043e\u0431\u044a\u0435\u043a\u0442\u0430 Author author = Author(name=author_name, bio=\"\") # \u0418\u0437\u0432\u043b\u0435\u0447\u0435\u043d\u0438\u0435 \u0441\u043f\u0438\u0441\u043a\u0430 \u043a\u043d\u0438\u0433 \u0438\u0437 JSON book_titles = data_dict.get('books') if not book_titles: raise ValueError(\"\u041d\u0435 \u0443\u043a\u0430\u0437\u0430\u043d \u0441\u043f\u0438\u0441\u043e\u043a \u043a\u043d\u0438\u0433 \u0434\u043b\u044f \u0441\u043e\u0445\u0440\u0430\u043d\u0435\u043d\u0438\u044f.\") # \u0421\u043e\u0437\u0434\u0430\u043d\u0438\u0435 \u043e\u0431\u044a\u0435\u043a\u0442\u043e\u0432 Book \u0438 \u0438\u0445 \u0434\u043e\u0431\u0430\u0432\u043b\u0435\u043d\u0438\u0435 \u043a \u0430\u0432\u0442\u043e\u0440\u0443 books = [Book(title=title, description=\"\", author=author) for title in book_titles] # \u0414\u043e\u0431\u0430\u0432\u043b\u0435\u043d\u0438\u0435 \u043e\u0431\u044a\u0435\u043a\u0442\u043e\u0432 \u0432 \u0441\u0435\u0441\u0441\u0438\u044e session.add(author) session.add_all(books) # \u0421\u043e\u0445\u0440\u0430\u043d\u0435\u043d\u0438\u0435 \u0438\u0437\u043c\u0435\u043d\u0435\u043d\u0438\u0439 session.commit() session.refresh(author) return author, books finally: # \u0417\u0430\u043a\u0440\u044b\u0442\u0438\u0435 \u0441\u0435\u0441\u0441\u0438\u0438 session.close() async def save_author_and_books_from_json(data: str): # \u0414\u0435\u043a\u043e\u0434\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u0435 JSON-\u0434\u0430\u043d\u043d\u044b\u0445 data_dict = json.loads(data) # \u0421\u043e\u0437\u0434\u0430\u043d\u0438\u0435 \u0430\u0441\u0438\u043d\u0445\u0440\u043e\u043d\u043d\u043e\u0439 \u0441\u0435\u0441\u0441\u0438\u0438 async with AsyncSession(engine) as session: # \u0418\u0437\u0432\u043b\u0435\u0447\u0435\u043d\u0438\u0435 \u0434\u0430\u043d\u043d\u044b\u0445 \u043e\u0431 \u0430\u0432\u0442\u043e\u0440\u0435 \u0438\u0437 JSON author_name = data_dict.get('author_name') if not author_name: raise ValueError(\"\u041d\u0435\u0434\u043e\u0441\u0442\u0430\u0442\u043e\u0447\u043d\u043e \u0434\u0430\u043d\u043d\u044b\u0445 \u0434\u043b\u044f \u0441\u043e\u0445\u0440\u0430\u043d\u0435\u043d\u0438\u044f.\") # \u0421\u043e\u0437\u0434\u0430\u043d\u0438\u0435 \u043e\u0431\u044a\u0435\u043a\u0442\u0430 Author author = Author(name=author_name, bio=\"\") # \u0418\u0437\u0432\u043b\u0435\u0447\u0435\u043d\u0438\u0435 \u0441\u043f\u0438\u0441\u043a\u0430 \u043a\u043d\u0438\u0433 \u0438\u0437 JSON book_titles = data_dict.get('books') if not book_titles: raise ValueError(\"\u041d\u0435 \u0443\u043a\u0430\u0437\u0430\u043d \u0441\u043f\u0438\u0441\u043e\u043a \u043a\u043d\u0438\u0433 \u0434\u043b\u044f \u0441\u043e\u0445\u0440\u0430\u043d\u0435\u043d\u0438\u044f.\") # \u0421\u043e\u0437\u0434\u0430\u043d\u0438\u0435 \u043e\u0431\u044a\u0435\u043a\u0442\u043e\u0432 Book \u0438 \u0438\u0445 \u0434\u043e\u0431\u0430\u0432\u043b\u0435\u043d\u0438\u0435 \u043a \u0430\u0432\u0442\u043e\u0440\u0443 books = [Book(title=title, description=\"\", author=author) for title in book_titles] # \u0414\u043e\u0431\u0430\u0432\u043b\u0435\u043d\u0438\u0435 \u043e\u0431\u044a\u0435\u043a\u0442\u043e\u0432 \u0432 \u0441\u0435\u0441\u0441\u0438\u044e session.add(author) session.add_all(books) # \u0421\u043e\u0445\u0440\u0430\u043d\u0435\u043d\u0438\u0435 \u0438\u0437\u043c\u0435\u043d\u0435\u043d\u0438\u0439 await session.commit() # \u0417\u0430\u043f\u0440\u043e\u0441 \u043d\u0430 \u043f\u043e\u043b\u0443\u0447\u0435\u043d\u0438\u0435 \u0441\u043e\u0445\u0440\u0430\u043d\u0435\u043d\u043d\u043e\u0433\u043e \u0430\u0432\u0442\u043e\u0440\u0430 await session.refresh(author) return author, books","title":"\u0424\u0443\u043d\u043a\u0446\u0438\u0438 \u0434\u043b\u044f \u0441\u043e\u0445\u0440\u0430\u043d\u0435\u043d\u0438\u044f \u0434\u0430\u043d\u043d\u044b\u0445 \u0432 \u0431\u0434"},{"location":"task2/#async","text":"import asyncio import aiohttp import json from save_data_async import save_author_and_books_from_json from async_parser import parse_author_info import time # \u0421\u043f\u0438\u0441\u043e\u043a URL-\u0430\u0434\u0440\u0435\u0441\u043e\u0432 \u0434\u043b\u044f \u043f\u0430\u0440\u0441\u0438\u043d\u0433\u0430 urls = [\"https://www.litres.ru/author/patrik-king/\", \"https://www.litres.ru/author/vladimir-pozner/\", \"https://www.litres.ru/author/allan-dib/\"] async def parse_and_save(url): author_info = await parse_author_info(url) await save_author_and_books_from_json(author_info) async def main(): start_time = time.time() tasks = [] for url in urls: task = asyncio.create_task(parse_and_save(url)) tasks.append(task) await asyncio.gather(*tasks) end_time = time.time() print(f\"\u0412\u0440\u0435\u043c\u044f \u0432\u044b\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u044f: {end_time - start_time} \u0441\u0435\u043a\u0443\u043d\u0434\") if __name__ == \"__main__\": asyncio.run(main())","title":"Async"},{"location":"task2/#multiprocessing","text":"import multiprocessing from parser import parse_author_info from save_data import save_author_and_books_from_json import time # \u0421\u043f\u0438\u0441\u043e\u043a URL-\u0430\u0434\u0440\u0435\u0441\u043e\u0432 \u0434\u043b\u044f \u043f\u0430\u0440\u0441\u0438\u043d\u0433\u0430 urls = [ \"https://www.litres.ru/author/patrik-king/\", \"https://www.litres.ru/author/vladimir-pozner/\", \"https://www.litres.ru/author/allan-dib/\" ] # \u0424\u0443\u043d\u043a\u0446\u0438\u044f \u0434\u043b\u044f \u043f\u0430\u0440\u0430\u043b\u043b\u0435\u043b\u044c\u043d\u043e\u0433\u043e \u043f\u0430\u0440\u0441\u0438\u043d\u0433\u0430 \u0438 \u0441\u043e\u0445\u0440\u0430\u043d\u0435\u043d\u0438\u044f \u0434\u0430\u043d\u043d\u044b\u0445 def parallel_parse_and_save(chunk): for url in chunk: author_info = parse_author_info(url) save_author_and_books_from_json(author_info) # \u0424\u0443\u043d\u043a\u0446\u0438\u044f \u0434\u043b\u044f \u0437\u0430\u0441\u0435\u0447\u0435\u043d\u0438\u044f \u0432\u0440\u0435\u043c\u0435\u043d\u0438 \u0438\u0441\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u044f \u0438 \u0437\u0430\u043f\u0443\u0441\u043a\u0430 \u043f\u0430\u0440\u0441\u0438\u043d\u0433\u0430 def measure_execution_time(): start_time = time.time() # \u0420\u0430\u0437\u0434\u0435\u043b\u0435\u043d\u0438\u0435 \u0441\u043f\u0438\u0441\u043a\u0430 URL-\u0430\u0434\u0440\u0435\u0441\u043e\u0432 \u043d\u0430 \u0440\u0430\u0432\u043d\u044b\u0435 \u0447\u0430\u0441\u0442\u0438 (chunks) num_processes = len(urls) chunk_size = len(urls) // num_processes chunks = [urls[i:i+chunk_size] for i in range(0, len(urls), chunk_size)] # \u0421\u043e\u0437\u0434\u0430\u043d\u0438\u0435 \u043f\u0440\u043e\u0446\u0435\u0441\u0441\u043e\u0432 \u0434\u043b\u044f \u043f\u0430\u0440\u0430\u043b\u043b\u0435\u043b\u044c\u043d\u043e\u0433\u043e \u043f\u0430\u0440\u0441\u0438\u043d\u0433\u0430 processes = [] for chunk in chunks: process = multiprocessing.Process(target=parallel_parse_and_save, args=(chunk,)) processes.append(process) process.start() # \u041e\u0436\u0438\u0434\u0430\u043d\u0438\u0435 \u0437\u0430\u0432\u0435\u0440\u0448\u0435\u043d\u0438\u044f \u0432\u0441\u0435\u0445 \u043f\u0440\u043e\u0446\u0435\u0441\u0441\u043e\u0432 for process in processes: process.join() end_time = time.time() execution_time = end_time - start_time print(f\"Execution time: {execution_time} seconds\") if __name__ == '__main__': # \u0412\u044b\u0437\u043e\u0432 \u0444\u0443\u043d\u043a\u0446\u0438\u0438 \u0434\u043b\u044f \u0437\u0430\u0441\u0435\u0447\u0435\u043d\u0438\u044f \u0432\u0440\u0435\u043c\u0435\u043d\u0438 \u0438\u0441\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u044f \u0438 \u0437\u0430\u043f\u0443\u0441\u043a\u0430 \u043f\u0430\u0440\u0441\u0438\u043d\u0433\u0430 measure_execution_time()","title":"Multiprocessing"},{"location":"task2/#threading","text":"import threading from parser import parse_author_info from save_data import save_author_and_books_from_json import time # \u0421\u043f\u0438\u0441\u043e\u043a URL-\u0430\u0434\u0440\u0435\u0441\u043e\u0432 \u0434\u043b\u044f \u043f\u0430\u0440\u0441\u0438\u043d\u0433\u0430 urls = [ \"https://www.litres.ru/author/patrik-king/\", \"https://www.litres.ru/author/vladimir-pozner/\", \"https://www.litres.ru/author/allan-dib/\" ] # \u0424\u0443\u043d\u043a\u0446\u0438\u044f \u0434\u043b\u044f \u043f\u0430\u0440\u0430\u043b\u043b\u0435\u043b\u044c\u043d\u043e\u0433\u043e \u043f\u0430\u0440\u0441\u0438\u043d\u0433\u0430 \u0438 \u0441\u043e\u0445\u0440\u0430\u043d\u0435\u043d\u0438\u044f \u0434\u0430\u043d\u043d\u044b\u0445 def parallel_parse_and_save(urls): for url in urls: author_info = parse_author_info(url) save_author_and_books_from_json(author_info) # \u0424\u0443\u043d\u043a\u0446\u0438\u044f \u0434\u043b\u044f \u0437\u0430\u0441\u0435\u0447\u0435\u043d\u0438\u044f \u0432\u0440\u0435\u043c\u0435\u043d\u0438 \u0438\u0441\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u044f \u0438 \u0437\u0430\u043f\u0443\u0441\u043a\u0430 \u043f\u0430\u0440\u0441\u0438\u043d\u0433\u0430 def measure_execution_time(): start_time = time.time() # \u0420\u0430\u0437\u0434\u0435\u043b\u0435\u043d\u0438\u0435 \u0441\u043f\u0438\u0441\u043a\u0430 URL-\u0430\u0434\u0440\u0435\u0441\u043e\u0432 \u043d\u0430 \u0440\u0430\u0432\u043d\u044b\u0435 \u0447\u0430\u0441\u0442\u0438 num_threads = 3 chunk_size = len(urls) // num_threads chunks = [urls[i:i + chunk_size] for i in range(0, len(urls), chunk_size)] # \u0417\u0430\u043f\u0443\u0441\u043a \u043f\u0430\u0440\u0430\u043b\u043b\u0435\u043b\u044c\u043d\u043e\u0433\u043e \u043f\u0430\u0440\u0441\u0438\u043d\u0433\u0430 \u0434\u043b\u044f \u043a\u0430\u0436\u0434\u043e\u0439 \u0447\u0430\u0441\u0442\u0438 threads = [] for chunk in chunks: thread = threading.Thread(target=parallel_parse_and_save, args=(chunk,)) thread.start() threads.append(thread) # \u041e\u0436\u0438\u0434\u0430\u043d\u0438\u0435 \u0437\u0430\u0432\u0435\u0440\u0448\u0435\u043d\u0438\u044f \u0432\u0441\u0435\u0445 \u043f\u043e\u0442\u043e\u043a\u043e\u0432 for thread in threads: thread.join() end_time = time.time() execution_time = end_time - start_time print(f\"Execution time: {execution_time} seconds\") # \u0412\u044b\u0437\u043e\u0432 \u0444\u0443\u043d\u043a\u0446\u0438\u0438 \u0434\u043b\u044f \u0437\u0430\u0441\u0435\u0447\u0435\u043d\u0438\u044f \u0432\u0440\u0435\u043c\u0435\u043d\u0438 \u0438\u0441\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u044f \u0438 \u0437\u0430\u043f\u0443\u0441\u043a\u0430 \u043f\u0430\u0440\u0441\u0438\u043d\u0433\u0430 measure_execution_time()","title":"Threading"},{"location":"task2/#_4","text":"\u0420\u0430\u0441\u0445\u043e\u0434 \u0440\u0435\u0441\u0443\u0440\u0441\u043e\u0432 \u043d\u0430 \u043c\u0443\u043b\u044c\u0442\u0438\u043f\u0440\u043e\u0446\u0435\u0441\u0441\u0438\u043d\u0433 \u043d\u0435 \u043e\u043f\u0440\u0430\u0432\u0434\u0430\u043d, \u043f\u043e\u044d\u0442\u043e\u043c\u0443 \u043e\u043d \u043e\u0442\u0440\u0430\u0431\u0430\u0442\u044b\u0432\u0435\u0442 \u0434\u043e\u043b\u044c\u0448\u0435. Async and threading \u043e\u0442\u0440\u0430\u0431\u0430\u0442\u044b\u0432\u0430\u044e\u0442 \u043f\u0440\u0438\u043c\u0435\u0440\u043d\u043e \u043e\u0434\u0438\u043d\u0430\u043a\u043e\u0432\u043e.","title":"\u0420\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u044b"}]}